{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "727f1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_embeddings_from_file = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "966ad518-7129-4e4c-927b-12743b19c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using Conda, you need to install this manually by cloning Ariel's repo, cd-ing to it, and running:\n",
    "#   /Users/ariellubonja/anaconda3/envs/faiss/bin/python (i.e. path to your Conda environment's python) setup.py install\n",
    "from biobert_embedding.embedding import BiobertEmbedding\n",
    "from utils import graph_tools\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import dask.bag as db\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "# import faiss\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c9d4de-f4e1-42bf-a6a8-31521cee4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_drug_names = list(graph_tools.get_unique_drugs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12f9043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client() # Dask client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "073a1da6-f4b9-46d5-9f36-8135c77c6252",
   "metadata": {},
   "source": [
    "## Original pip install biobert-embedding does not work (it's too old)\n",
    "\n",
    "I forked the repo. Install using `pip install git+https://github.com/ariellubonja/biobert_embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a8fab6-27d9-421c-8c03-d2b7333fa481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing models/pytorch_model.bin\n",
      "Using existing models/config.json\n",
      "Using existing models/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "biobert = BiobertEmbedding()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "417978d6-9447-431c-8b53-7e2e2ccb9ea6",
   "metadata": {},
   "source": [
    "### Word Embeddings of Drugs.com drug names (without supporting text)\n",
    "\n",
    "Find the drug names I've crawled [here](https://drive.google.com/drive/folders/1EO659a-tyjfXjKzHk-M0WreZBR14MgRM?usp=sharing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad1705e2",
   "metadata": {},
   "source": [
    "<font color=\"orange\">The cell below will try to handle Out of Vocabulary terms. This means that the embedding matrix is not a clear matrix, but will be a list of Tensors</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509bd66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_embeddings_from_file:\n",
    "    biobert_embeddings_oov = torch.load('outputs/biobert_oov_embeddings.pt')\n",
    "else:\n",
    "    # This will take a while\n",
    "    client = Client()\n",
    "    \n",
    "    # db - Dask Bag\n",
    "    b = db.from_sequence(unique_drug_names)\n",
    "\n",
    "    # Map the function to the data\n",
    "    biobert_embeddings_oov = b.map(biobert.word_vector).compute()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # biobert_embeddings_oov = list(map(biobert.word_vector, unique_drug_names)) # Single-threaded\n",
    "    # Out of vocabulary will be split into smaller. May end up with multiple embeddings for each word. Parallelized\n",
    "\n",
    "    # Using Python's native multiprocessing library\n",
    "    # biobert_embeddings_oov = pool.map(biobert.word_vector, unique_drug_names)\n",
    "\n",
    "    # pool.close()\n",
    "    # pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d325f7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(biobert_embeddings_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc6dcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(biobert_embeddings_oov, 'outputs/biobert_oov_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96769e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(biobert_embeddings_oov, index=unique_drug_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f872735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>glycron</th>\n",
       "      <td>[tensor(11.4696), tensor(-0.7767), tensor(0.04...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fioricet-with-codeine</th>\n",
       "      <td>[tensor(-0.3252), tensor(-2.0265), tensor(0.87...</td>\n",
       "      <td>[tensor(0.0035), tensor(-0.4583), tensor(0.225...</td>\n",
       "      <td>[tensor(0.2675), tensor(0.0342), tensor(-1.016...</td>\n",
       "      <td>[tensor(-0.1575), tensor(-0.5886), tensor(0.13...</td>\n",
       "      <td>[tensor(0.0583), tensor(0.8732), tensor(3.1608...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocella</th>\n",
       "      <td>[tensor(-1.5729), tensor(-2.2441), tensor(-3.9...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorophyllin</th>\n",
       "      <td>[tensor(6.9570), tensor(-19.1814), tensor(-3.4...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eskata</th>\n",
       "      <td>[tensor(2.8071), tensor(-2.8373), tensor(-0.72...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      0   \\\n",
       "glycron                [tensor(11.4696), tensor(-0.7767), tensor(0.04...   \n",
       "fioricet-with-codeine  [tensor(-0.3252), tensor(-2.0265), tensor(0.87...   \n",
       "ocella                 [tensor(-1.5729), tensor(-2.2441), tensor(-3.9...   \n",
       "chlorophyllin          [tensor(6.9570), tensor(-19.1814), tensor(-3.4...   \n",
       "eskata                 [tensor(2.8071), tensor(-2.8373), tensor(-0.72...   \n",
       "\n",
       "                                                                      1   \\\n",
       "glycron                                                             None   \n",
       "fioricet-with-codeine  [tensor(0.0035), tensor(-0.4583), tensor(0.225...   \n",
       "ocella                                                              None   \n",
       "chlorophyllin                                                       None   \n",
       "eskata                                                              None   \n",
       "\n",
       "                                                                      2   \\\n",
       "glycron                                                             None   \n",
       "fioricet-with-codeine  [tensor(0.2675), tensor(0.0342), tensor(-1.016...   \n",
       "ocella                                                              None   \n",
       "chlorophyllin                                                       None   \n",
       "eskata                                                              None   \n",
       "\n",
       "                                                                      3   \\\n",
       "glycron                                                             None   \n",
       "fioricet-with-codeine  [tensor(-0.1575), tensor(-0.5886), tensor(0.13...   \n",
       "ocella                                                              None   \n",
       "chlorophyllin                                                       None   \n",
       "eskata                                                              None   \n",
       "\n",
       "                                                                      4   \\\n",
       "glycron                                                             None   \n",
       "fioricet-with-codeine  [tensor(0.0583), tensor(0.8732), tensor(3.1608...   \n",
       "ocella                                                              None   \n",
       "chlorophyllin                                                       None   \n",
       "eskata                                                              None   \n",
       "\n",
       "                         5     6     7     8     9   ...    15    16    17  \\\n",
       "glycron                None  None  None  None  None  ...  None  None  None   \n",
       "fioricet-with-codeine  None  None  None  None  None  ...  None  None  None   \n",
       "ocella                 None  None  None  None  None  ...  None  None  None   \n",
       "chlorophyllin          None  None  None  None  None  ...  None  None  None   \n",
       "eskata                 None  None  None  None  None  ...  None  None  None   \n",
       "\n",
       "                         18    19    20    21    22    23    24  \n",
       "glycron                None  None  None  None  None  None  None  \n",
       "fioricet-with-codeine  None  None  None  None  None  None  None  \n",
       "ocella                 None  None  None  None  None  None  None  \n",
       "chlorophyllin          None  None  None  None  None  None  None  \n",
       "eskata                 None  None  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ccf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"outputs/biobert_oov_embeddings.npy\", biobert_embeddings_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53676f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biobert_embeddings_oov[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e1c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3310"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the indices of the drug names that have only one embedding, i.e. the drug name is in the Vocabulary\n",
    "vector_embd_indices = [i for i, num in enumerate(biobert_embeddings_oov) if len(num) == 1]\n",
    "len(vector_embd_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57811b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biobert_embeddings_oov) == len(unique_drug_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_embeddings = torch.stack([biobert_embeddings_oov[i][0] for i in vector_embd_indices]).numpy()\n",
    "corresponding_drug_names = [unique_drug_names[i] for i in vector_embd_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cad206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3310, 768)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_embeddings.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc12e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trilafon</th>\n",
       "      <td>-2.494238</td>\n",
       "      <td>-5.982688</td>\n",
       "      <td>3.391733</td>\n",
       "      <td>-3.165889</td>\n",
       "      <td>-3.972550</td>\n",
       "      <td>-3.434661</td>\n",
       "      <td>2.095402</td>\n",
       "      <td>1.464997</td>\n",
       "      <td>6.532821</td>\n",
       "      <td>-1.086071</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.374193</td>\n",
       "      <td>3.749851</td>\n",
       "      <td>1.355658</td>\n",
       "      <td>-2.396497</td>\n",
       "      <td>3.676836</td>\n",
       "      <td>1.897683</td>\n",
       "      <td>0.468625</td>\n",
       "      <td>6.310996</td>\n",
       "      <td>-9.883236</td>\n",
       "      <td>-1.279147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calcipotriene</th>\n",
       "      <td>4.240830</td>\n",
       "      <td>1.769997</td>\n",
       "      <td>-0.795535</td>\n",
       "      <td>-6.929158</td>\n",
       "      <td>5.979644</td>\n",
       "      <td>-0.761292</td>\n",
       "      <td>-1.656379</td>\n",
       "      <td>0.054974</td>\n",
       "      <td>0.432746</td>\n",
       "      <td>12.672398</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.860700</td>\n",
       "      <td>-1.191983</td>\n",
       "      <td>-9.798771</td>\n",
       "      <td>-4.564957</td>\n",
       "      <td>-9.084117</td>\n",
       "      <td>-5.654516</td>\n",
       "      <td>-0.909690</td>\n",
       "      <td>10.118820</td>\n",
       "      <td>-6.920544</td>\n",
       "      <td>3.411890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fosinopril</th>\n",
       "      <td>2.749605</td>\n",
       "      <td>-11.437942</td>\n",
       "      <td>2.700483</td>\n",
       "      <td>-0.598100</td>\n",
       "      <td>9.610103</td>\n",
       "      <td>-13.214931</td>\n",
       "      <td>4.708538</td>\n",
       "      <td>7.986394</td>\n",
       "      <td>-0.904664</td>\n",
       "      <td>-3.148977</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.771662</td>\n",
       "      <td>3.917134</td>\n",
       "      <td>-10.183059</td>\n",
       "      <td>5.208779</td>\n",
       "      <td>6.980632</td>\n",
       "      <td>0.385215</td>\n",
       "      <td>2.746163</td>\n",
       "      <td>-2.396154</td>\n",
       "      <td>-15.207134</td>\n",
       "      <td>-8.165861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nadostine</th>\n",
       "      <td>-2.403095</td>\n",
       "      <td>-5.212749</td>\n",
       "      <td>-2.980472</td>\n",
       "      <td>-4.289715</td>\n",
       "      <td>1.065220</td>\n",
       "      <td>-2.463279</td>\n",
       "      <td>2.731372</td>\n",
       "      <td>3.838523</td>\n",
       "      <td>-2.878551</td>\n",
       "      <td>3.916560</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.626741</td>\n",
       "      <td>4.469468</td>\n",
       "      <td>0.329026</td>\n",
       "      <td>1.498180</td>\n",
       "      <td>-2.434177</td>\n",
       "      <td>-1.255941</td>\n",
       "      <td>0.073906</td>\n",
       "      <td>2.629568</td>\n",
       "      <td>-7.653620</td>\n",
       "      <td>3.064509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duavee</th>\n",
       "      <td>-2.835025</td>\n",
       "      <td>-6.494714</td>\n",
       "      <td>2.831769</td>\n",
       "      <td>-5.364807</td>\n",
       "      <td>4.386308</td>\n",
       "      <td>-0.174934</td>\n",
       "      <td>3.309786</td>\n",
       "      <td>-0.848888</td>\n",
       "      <td>2.427666</td>\n",
       "      <td>7.614682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924215</td>\n",
       "      <td>1.525765</td>\n",
       "      <td>-0.303652</td>\n",
       "      <td>3.410230</td>\n",
       "      <td>0.926888</td>\n",
       "      <td>-4.464722</td>\n",
       "      <td>2.695533</td>\n",
       "      <td>6.594471</td>\n",
       "      <td>-3.707011</td>\n",
       "      <td>-5.687425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2         3         4          5    \\\n",
       "trilafon      -2.494238  -5.982688  3.391733 -3.165889 -3.972550  -3.434661   \n",
       "calcipotriene  4.240830   1.769997 -0.795535 -6.929158  5.979644  -0.761292   \n",
       "fosinopril     2.749605 -11.437942  2.700483 -0.598100  9.610103 -13.214931   \n",
       "nadostine     -2.403095  -5.212749 -2.980472 -4.289715  1.065220  -2.463279   \n",
       "duavee        -2.835025  -6.494714  2.831769 -5.364807  4.386308  -0.174934   \n",
       "\n",
       "                    6         7         8          9    ...        758  \\\n",
       "trilafon       2.095402  1.464997  6.532821  -1.086071  ...  -9.374193   \n",
       "calcipotriene -1.656379  0.054974  0.432746  12.672398  ... -10.860700   \n",
       "fosinopril     4.708538  7.986394 -0.904664  -3.148977  ...  -8.771662   \n",
       "nadostine      2.731372  3.838523 -2.878551   3.916560  ...  -5.626741   \n",
       "duavee         3.309786 -0.848888  2.427666   7.614682  ...   0.924215   \n",
       "\n",
       "                    759        760       761       762       763       764  \\\n",
       "trilafon       3.749851   1.355658 -2.396497  3.676836  1.897683  0.468625   \n",
       "calcipotriene -1.191983  -9.798771 -4.564957 -9.084117 -5.654516 -0.909690   \n",
       "fosinopril     3.917134 -10.183059  5.208779  6.980632  0.385215  2.746163   \n",
       "nadostine      4.469468   0.329026  1.498180 -2.434177 -1.255941  0.073906   \n",
       "duavee         1.525765  -0.303652  3.410230  0.926888 -4.464722  2.695533   \n",
       "\n",
       "                     765        766       767  \n",
       "trilafon        6.310996  -9.883236 -1.279147  \n",
       "calcipotriene  10.118820  -6.920544  3.411890  \n",
       "fosinopril     -2.396154 -15.207134 -8.165861  \n",
       "nadostine       2.629568  -7.653620  3.064509  \n",
       "duavee          6.594471  -3.707011 -5.687425  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(vector_embeddings, index=corresponding_drug_names)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a40d13a",
   "metadata": {},
   "source": [
    "## Evaluations\n",
    "\n",
    "Top-K similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90695fab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Instantiate an index with the desired index type and dimensionality\u001b[39;00m\n\u001b[1;32m      6\u001b[0m index \u001b[39m=\u001b[39m faiss\u001b[39m.\u001b[39mIndexFlatIP(\u001b[39m256\u001b[39m)  \u001b[39m# Cosine similarity, assuming 256-dimensional embeddings\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m biobert_embeddings_np \u001b[39m=\u001b[39m vector_embeddings\n\u001b[1;32m     10\u001b[0m \u001b[39m# Add biobert_embeddings_np to the index\u001b[39;00m\n\u001b[1;32m     11\u001b[0m index\u001b[39m.\u001b[39madd(biobert_embeddings_np)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vector_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate an index with the desired index type and dimensionality\n",
    "index = faiss.IndexFlatIP(768)  # Cosine similarity\n",
    "\n",
    "biobert_embeddings_np = df.values\n",
    "\n",
    "# Add biobert_embeddings_np to the index\n",
    "index.add(biobert_embeddings_np)\n",
    "\n",
    "# number of nearest neighbors\n",
    "k = 5\n",
    "\n",
    "# similarity search\n",
    "# D contains the similarities to the nearest neighbors (cosine similarity)\n",
    "# I contains the indices of the nearest neighbors (excluding self)\n",
    "D, I = index.search(biobert_embeddings_np, k+1)  # Retrieve k+1 neighbors to exclude self\n",
    "\n",
    "\n",
    "for i in range(biobert_embeddings_np.shape[0]): # Iterate over each embedding\n",
    "    embedding = biobert_embeddings_np[i]\n",
    "    nearest_indices = I[i][1:]  # Exclude self, start from index 1\n",
    "    nearest_similarities = D[i][1:]\n",
    "\n",
    "    # Print the top-k nearest neighbors for the current embedding\n",
    "    print(f\"Embedding {df.index[i]}:\")\n",
    "    for j, index in enumerate(nearest_indices):\n",
    "        similarity = nearest_similarities[j]\n",
    "        print(f\"Nearest Neighbor {j+1}: Drug Name {df.index[index]}, Similarity {similarity}\")\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef7e3795",
   "metadata": {},
   "source": [
    "## 3194 of the Drugs have vector embeddings, whereas the rest return a Matrix that we have to deal with using Pooling\n",
    "\n",
    "Let's see the 3194"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e16c7ec8",
   "metadata": {},
   "source": [
    "<font color=\"red\">Most of the drugs give a matrix as their embedding, and not a vector.</font>\n",
    "\n",
    "Need to try various pooling methods to get a vector from the matrix + see what is best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cb57841-87c8-441c-8847-96abec59cced",
   "metadata": {},
   "source": [
    "## TODO try ClinicalBERT https://github.com/EmilyAlsentzer/clinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdfdda59-4fe6-49f4-ad18-b2c8e248ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ariellubonja/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83af139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(unique_drug_names, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85a3181b",
   "metadata": {},
   "source": [
    "Macbook M1 Pro Runtimes\n",
    "\n",
    "CPU - 1min 17 sec\n",
    "\n",
    "MPS (torch 1.13) - Uses way too much memory (50GB+ - crashes) whereas CPU is max 13GB\n",
    "\n",
    "MPS (torch 2.01) - 1min 15s - 18GB memory usage\n",
    "\n",
    "\n",
    "<font color=\"red\">Conclusion - not useful yet!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d8eaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 15s ± 8.66 s per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_inputs)\n",
    "    embeddings = model_output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb4c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7befa08-cb7f-4b6a-8a4d-dc54462213f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
